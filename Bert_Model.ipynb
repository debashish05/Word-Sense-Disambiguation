{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFpIkeyBi7hh",
        "outputId": "1c690e45-e079-449e-eed0-e8ee45151ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os, sys \n",
        "#to be able to interact with Google Drive's operating system\n",
        "from google.colab import drive \n",
        "#drive is a module that allows us use Python to interact with google drive\n",
        "drive.mount('/content/gdrive') \n",
        "#mounting google drive allows us to work with its contents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p66SVX4XcovR"
      },
      "outputs": [],
      "source": [
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/gdrive/MyDrive/Colab Notebooks', nb_path)\n",
        "#sys.path.insert(0, nb_path)  # or \n",
        "sys.path.append(nb_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQyl7lppInq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0356b435-8fef-4bee-a5ac-8746d738a3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.11.0+cu113)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.6)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.22.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.2.0)\n",
            "Collecting botocore<1.26.0,>=1.25.4\n",
            "  Downloading botocore-1.25.4-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 34.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3->pytorch-transformers) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.4->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.22.4 botocore-1.25.4 jmespath-1.0.0 pytorch-transformers-1.2.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install  pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uy5g9bYARMd"
      },
      "outputs": [],
      "source": [
        "import pytorch_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVYRsid0E9G5"
      },
      "outputs": [],
      "source": [
        "import os,glob,pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm,trange\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus.reader.wordnet import WordNetError\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from pytorch_transformers import BertTokenizer, Adam\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torch import nn\n",
        "from torch import arange, zeros_like\n",
        "from pytorch_transformers import BertModel, BertConfig\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWSE7YPUFJ7B"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHnoNKgMlp66"
      },
      "outputs": [],
      "source": [
        "#!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WzYKfAJFGot"
      },
      "outputs": [],
      "source": [
        "#repo = git.Repo.clone_from(\"https://github.com/rubenIzquierdo/wsd_corpora.git\", \"./data/raw/wsd_corpora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wTl5e3HHiN8"
      },
      "outputs": [],
      "source": [
        "#shutil.copytree(r\"./data/raw/wsd_corpora/semcor3.0\", r\"./data/raw/semcor3.0\")\n",
        "#shutil.copytree(r\"./data/raw/wsd_corpora/semeval2007_task17_allwords\", r\"./data/raw/semeval2007_task17_allwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-fsyJqgHnmu"
      },
      "outputs": [],
      "source": [
        "def xml_parse(_fpath):\n",
        "\n",
        "    \n",
        "    sctree = ET.parse(_fpath)\n",
        "\n",
        "    # Iterates over list of words in files    \n",
        "    dct_list1 = []\n",
        "    for node in sctree.iter('wf'):\n",
        "        attributes = node.attrib\n",
        "        attributes['text'] = node.text\n",
        "        dct_list1.append(attributes)\n",
        "\n",
        "    # Iterates over terms to find senses and corresponding sense references\n",
        "    dct_list2 = []\n",
        "    for term in sctree.iter('term'):\n",
        "        lemma = term.attrib.get('lemma')\n",
        "        wordid = term.find('span/target').attrib.get('id')\n",
        "        pos = ''\n",
        "\n",
        "        wnsn = '0'\n",
        "        senseid=''\n",
        "        if term.findall('externalReferences/externalRef'):\n",
        "            wnsn = term.findall('externalReferences/externalRef')[0].attrib.get('reference')\n",
        "            senseid = term.findall('externalReferences/externalRef')[1].attrib.get('reference')\n",
        "        dct_list2.append({'id':wordid,'lemma':lemma,'wn_sense_num':wnsn,'lexical_key':senseid,'pos':term.attrib['pos']})\n",
        "\n",
        "    word_df = pd.DataFrame(dct_list1)\n",
        "    sense_ref_df = pd.DataFrame(dct_list2)   \n",
        "    \n",
        "    return pd.merge(word_df,sense_ref_df,on='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jGUIuilHp9N"
      },
      "outputs": [],
      "source": [
        "def gen_file_list(_basepath,ext='*.naf'):    \n",
        "    file_list = []\n",
        "    fla = glob.glob(os.path.join(_basepath,ext))\n",
        "    flb = glob.glob(os.path.join(_basepath,'*',ext))\n",
        "    flc = glob.glob(os.path.join(_basepath,'**',ext))\n",
        "    files = set(fla+flb+flc)\n",
        "    for fileref in files: #search recursively for files\n",
        "        parent_folder_name = pathlib.Path(fileref).parent.name\n",
        "        file_name = pathlib.Path(fileref).name.split('.')[0]\n",
        "        \n",
        "        file_list.append( {'file_path':fileref,\n",
        "                           'parent_folder':parent_folder_name,\n",
        "                           'file_name':file_name})\n",
        "\n",
        "    return pd.DataFrame(file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuBPcEQCHq45"
      },
      "outputs": [],
      "source": [
        "def parse_corpus(_basepath,filter_validation = False):\n",
        "\n",
        "   # generate dataframe with references to all files\n",
        "    _fpath_df = gen_file_list(_basepath)\n",
        "    \n",
        "    # filter to remove validation files\n",
        "    filtered_file_df = _fpath_df\n",
        "    if filter_validation:\n",
        "         filtered_file_df = _fpath_df[_fpath_df.parent_folder != 'brownv']\n",
        "    \n",
        "    _dflist = []\n",
        "    for i,file_entry in tqdm(filtered_file_df.iterrows(), total=filtered_file_df.shape[0]):\n",
        "        _parsed_file_df = xml_parse_semcor(file_entry.file_path)\n",
        "        _parsed_file_df['file'] = file_entry.file_name\n",
        "        _dflist.append(_parsed_file_df)\n",
        "\n",
        "    return pd.concat(_dflist)[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vol1KLRhHuF8"
      },
      "outputs": [],
      "source": [
        "def build_corpus(_basepath,verbose=True,**kwargs):\n",
        "\n",
        "    if verbose: print('Parsing corpus')\n",
        "    base_corpus = parse_corpus(_basepath,**kwargs)\n",
        "\n",
        "    # Build wordnet ref key using wordnet lemma\n",
        "    if verbose: print('Preprocessing indexes...',end=\"\")\n",
        "    base_corpus['wn_index'] = base_corpus['lemma']+'%'+base_corpus['lexical_key']\n",
        "\n",
        "    base_corpus.loc[base_corpus.lexical_key == '','wn_index'] = ''\n",
        "    base_corpus.drop('lexical_key',axis=1,inplace=True)\n",
        "    if verbose: print('Done!')\n",
        "    return base_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Locznd4LHwOd"
      },
      "outputs": [],
      "source": [
        "def wordnet_get_glosses(_word,_sense_id):\n",
        "\n",
        "    _sense_id = int(_sense_id)\n",
        "    if not _word: # if ref is empty\n",
        "        return ''\n",
        "    try:\n",
        "        all_synsets = wn.synsets(_word)\n",
        "        target_gloss = []\n",
        "        other_glosses = []\n",
        "        for syn in all_synsets:\n",
        "            split = syn.name().split('.')\n",
        "            wn_lemma = split[0]\n",
        "            sense_num = int(split[-1])\n",
        "            #if _word == wn_lemma:    \n",
        "            if sense_num == _sense_id:\n",
        "                target_gloss.append(syn.definition()) \n",
        "            else:\n",
        "                other_glosses.append(syn.definition())                \n",
        "        return target_gloss,other_glosses[:2]\n",
        "    except (AttributeError,WordNetError,ValueError) as err:\n",
        "        return 'WN Error',None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYrJNnw0HyPO"
      },
      "outputs": [],
      "source": [
        "def wordnet_gloss_helper(_word,_sense_id):\n",
        "\n",
        "  if not _word or not _sense_id:\n",
        "      return '',''\n",
        "  senseidlist = _sense_id.split(';')\n",
        "  if len(senseidlist) == 1:\n",
        "      return wordnet_get_glosses(_word,int(_sense_id))\n",
        "  elif len(senseidlist) > 1:\n",
        "      list_proper_glosses = []\n",
        "      other_gloss_set = set()\n",
        "      for senseid in senseidlist:\n",
        "          gloss, other_glosses =  wordnet_get_glosses(_word,int(senseid))\n",
        "          if gloss:\n",
        "              list_proper_glosses.append(gloss)\n",
        "              other_gloss_set.update(set(other_glosses))\n",
        "      # if one of the glosses is bogus return only one\n",
        "      if len(list_proper_glosses) == 1:\n",
        "          return list_proper_glosses[0], other_gloss_set\n",
        "      return list_proper_glosses, other_gloss_set\n",
        "  else:\n",
        "      return  'WN Error',[]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JY__AxCH0qv"
      },
      "outputs": [],
      "source": [
        "def add_wordnet_gloss(_semcordf,verbose=True):\n",
        "\n",
        "    #if verbose: print('Adding wordnet glosses')\n",
        "    _semcordf['idx'] = list(range(len(_semcordf))) #adding index for merging\n",
        "    tqdm.pandas(desc=\"Gloss preprocessing\") \n",
        "    _glosses = _semcordf[_semcordf.wn_sense_num != '0'].progress_apply(lambda _row: (*wordnet_gloss_helper(_row['lemma'],_row['wn_sense_num'])\\\n",
        "                                                                        ,_row['idx']),axis=1 )\n",
        "    _df_glosses = pd.DataFrame(_glosses.values.tolist(),columns=['gloss','other_glosses','idx'])\n",
        "    _merged = pd.merge(_semcordf,_df_glosses,on='idx',how='left').fillna('')\n",
        "    # for now take only first gloss\n",
        "    _merged['gloss'] = _merged.gloss.apply(lambda x: x[0] if x else '')\n",
        "    # tag how many other glosses there are\n",
        "    _merged['other_glossesnum'] = _merged.other_glosses.apply(lambda x: len(x))   \n",
        "    if verbose: print('Done!')\n",
        "    return _merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-F6aLwnH4TY"
      },
      "outputs": [],
      "source": [
        "def gen_sentence_context_pairs(_df):\n",
        "\n",
        "    concatenated_sentence = _df.text.str.cat(sep = ' ').replace(\" '\",\"'\")\n",
        "    basedct = {'context':concatenated_sentence,\n",
        "               #'sent':_df.iloc[0].sent,\n",
        "               'file':_df.iloc[0].file}\n",
        "\n",
        "    semcor_sentences = []\n",
        "\n",
        "    # Make sure there are other glosses and that the gloss column is not null\n",
        "    for i,line in _df[(_df.other_glossesnum > 0) & (_df.gloss != 'WN Error') & (_df.gloss != '')].iterrows(): \n",
        "\n",
        "        # First append the proper context to dct with label True\n",
        "        newbasedct = basedct.copy()\n",
        "        newbasedct['target_word'] = line.text\n",
        "        newbasedct['gloss'] = line.gloss\n",
        "        newbasedct['is_proper_gloss'] = True\n",
        "        semcor_sentences.append(newbasedct)\n",
        "        # Then append all different contexes with False labels\n",
        "        for other_glosses in line.other_glosses:\n",
        "            newbasedct = basedct.copy()\n",
        "            newbasedct['target_word'] = line.text\n",
        "            newbasedct['gloss'] = other_glosses\n",
        "            newbasedct['is_proper_gloss'] = False\n",
        "            semcor_sentences.append(newbasedct)\n",
        "                \n",
        "    return semcor_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU9nW34yH7pv"
      },
      "outputs": [],
      "source": [
        "def build_joint_dataset(_df):\n",
        "\n",
        "    groupbyobj = _df.groupby(['sent','file'])\n",
        "    full_dict_list = []\n",
        "    for [sentnum,file],gp in tqdm(groupbyobj,total=len(groupbyobj)):\n",
        "        full_dict_list.extend(gen_sentence_context_pairs(gp))\n",
        "    cols = ['file','context','target_word','gloss','is_proper_gloss']\n",
        "    return pd.DataFrame(full_dict_list)[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dEZnrcNH90u"
      },
      "outputs": [],
      "source": [
        "def build_joint_corpus(_basepath,verbose=True,byref=False):\n",
        "\n",
        "    semcor_corpus_df = build_corpus(_basepath,verbose=verbose)\n",
        "    semcor_corpus_df = add_wordnet_gloss(semcor_corpus_df,verbose=verbose)\n",
        "    if verbose: print('Processing adn labeling joint cintext-gloss pairs...',end=\"\")\n",
        "    final_corpus = build_joint_dataset(semcor_corpus_df)\n",
        "    if verbose: print('Done!')\n",
        "    final_corpus['gloss'] = final_corpus.gloss.apply(lambda x: x[0] if type(x) == list else x)\n",
        "    return final_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLHRqrkiIDfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce18f1e3-9d78-4c9c-f1b7-fda3e10f4266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing corpus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [01:13<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing indexes...Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gloss preprocessing: 100%|██████████| 2456/2456 [00:02<00:00, 872.15it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "Processing adn labeling joint cintext-gloss pairs..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 252/252 [00:00<00:00, 319.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "fpath = \"./notebooks/data/raw/semcor3.0/\"\n",
        "savepath = r\"./notebooks/data/preprocessed/semcor_gloss_Bert.pkl\"\n",
        "final_corpus = build_joint_corpus(fpath)\n",
        "final_corpus.to_pickle(savepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWM3shCuIINh"
      },
      "outputs": [],
      "source": [
        "data_path=\"./notebooks/data/preprocessed/semcor_gloss_Bert.pkl\" \n",
        "default_save_path='..\\data'\n",
        "weak_supervision=True\n",
        "preprocess_inputs=True\n",
        "token_layer='sent-cls-ws'\n",
        "batch_size=128\n",
        "val_check_interval=0.05\n",
        "model_type='bert-base-uncased'\n",
        "lr=2e-5\n",
        "weight_decay=0.01\n",
        "epochs=4\n",
        "input_len=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KQY07JGIMh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "970de259-ba01-488c-8580-2bde5e8f6c30"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-8a7919772c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_type)\n",
        "train_dataset = pd.read_pickle(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjRzHQKEBp24"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4D40SJ2IOb8"
      },
      "outputs": [],
      "source": [
        "def format_sentences_BERT(_row):\n",
        "    return '[CLS] '+_row.loc['context']+' [SEP] '+_row.loc['gloss']+' [SEP]'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpAiBFSCIQYf"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_index(_df,output_len=128,tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
        "                       display_progress = True,formatting_method=format_sentences_BERT):\n",
        "   \n",
        "    tqdm.pandas(desc=\"Sentence preprocessing\")    \n",
        "    _df.loc[:,'preproc_sent'] = _df.progress_apply(formatting_method,axis=1)\n",
        "    tqdm.pandas(desc=\"Sentence Tokenization\")\n",
        "    _df.loc[:,'tokenized_sent'] = _df.preproc_sent.progress_apply(tokenizer.tokenize)\n",
        "    tqdm.pandas(desc=\"Tokenizing target words\")\n",
        "    _df.loc[:,'tokenized_target_word'] = _df.target_word.progress_apply(lambda row: tokenizer.tokenize(row)[0])\n",
        "    tqdm.pandas(desc=\"Converting tokens to embeddings\")\n",
        "    _df.loc[:,'input_ids'] = _df.tokenized_sent.progress_apply(tokenizer.convert_tokens_to_ids)\n",
        "    \n",
        "    padded_input_ids = pad_sequences(_df['input_ids'], \n",
        "                                    maxlen=output_len, dtype=\"long\",padding = \"post\", truncating = \"post\")\n",
        "    _df.loc[:,'input_ids'] = np.split(padded_input_ids, _df.shape[0], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C22XNpqhIxlW"
      },
      "outputs": [],
      "source": [
        "def gen_sentence_indexes(_df,output_len=128):\n",
        "    \n",
        "    def get_index_of_sep(_row):\n",
        "        _index_sep_tokens = [i for i,word  in enumerate(_row['tokenized_sent']) \\\n",
        "                           if word == '[SEP]']\n",
        "        _sentence_indexes = np.array([0]*(_index_sep_tokens[0]+1)\\\n",
        "                                     +[1]*(_index_sep_tokens[1]-_index_sep_tokens[0]))\n",
        "        return _sentence_indexes\n",
        "    \n",
        "    tqdm.pandas(desc=\"Indexing sentences\") \n",
        "    _df.loc[:,'sent_indexes'] = _df.progress_apply(get_index_of_sep,axis=1)\n",
        "    padded_sent_idx = pad_sequences(_df['sent_indexes'],\n",
        "                                               maxlen=output_len, dtype=\"long\",\n",
        "                                               padding = \"post\", truncating = \"post\",value=1)\n",
        "    _df.loc[:,'sent_indexes'] = np.split(padded_sent_idx, _df.shape[0], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUNUMJVZIzfH"
      },
      "outputs": [],
      "source": [
        "def find_index_of_target_token(_df):\n",
        "    \"\"\"\n",
        "    looks for index of target token in the corresponding tokenized sentence\n",
        "    \n",
        "    \"\"\"\n",
        "    find_token = lambda  _row: [i for i,word  in \\\n",
        "                         enumerate(_row['tokenized_sent']) \\\n",
        "                         if word == _row['tokenized_target_word'].lower()]\n",
        "    tqdm.pandas(desc=\"Finding target token in sentence\") \n",
        "    _df.loc[:,'target_token_idx'] = _df.progress_apply(find_token,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oauTePFI1pk"
      },
      "outputs": [],
      "source": [
        "def preprocess_model_inputs(_df,sample_size=None, filter_bad_rows=True,\n",
        "                            output_len=128,\n",
        "                            tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),**kwargs):\n",
        "\n",
        "    \n",
        "    _smpldf = _df\n",
        "    if sample_size:\n",
        "        _smpldf = _df.sample(sample_size)\n",
        "    \n",
        "    tokenize_and_index(_smpldf,output_len=output_len,\n",
        "                       tokenizer=tokenizer)\n",
        "    gen_sentence_indexes(_smpldf,output_len=output_len)\n",
        "    find_index_of_target_token(_smpldf)\n",
        "\n",
        "        \n",
        "    if filter_bad_rows: # rows where the target word index is not found due to cutoff or exceeds tensor size \n",
        "        _smpldf = _smpldf[_smpldf.target_token_idx.apply(lambda x: len(x) !=  0)]\n",
        "        _smpldf = _smpldf[_smpldf.target_token_idx.apply(lambda x: x[0] <  output_len)]\n",
        "\n",
        "    \n",
        "    return _smpldf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfK-FxZhQN4c"
      },
      "outputs": [],
      "source": [
        "df_train = preprocess_model_inputs(train_dataset,tokenizer=tokenizer,output_len=input_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7WGkPimeB_K"
      },
      "outputs": [],
      "source": [
        "#preprocessedsavepath = \"./notebooks/data/preprocessed/preprocessed_semcor.pkl\"\n",
        "#df_train.to_pickle(preprocessedsavepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se8bfRwshK3u"
      },
      "outputs": [],
      "source": [
        "#preprocessedsavepath = 'data/preprocessed/preprocessed_semcor.pkl'\n",
        "#preprocessedsavepath='./notebooks/data/preprocessed/preprocessed_semcor.pkl'\n",
        "#df_train = pd.read_pickle(preprocessedsavepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiDNW-5Mrh5F"
      },
      "outputs": [],
      "source": [
        "class CorpusDataset(Dataset):\n",
        "    \"\"\"\n",
        "    pytorch dataset handling class    \n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.corpus_dataframe = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_dataframe.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.corpus_dataframe.iloc[idx]\n",
        "        return (torch.tensor(row['input_ids'][0]),  # Input token encodings\n",
        "                torch.tensor(row['sent_indexes'][0], dtype=torch.int64), # Sentence encoding\n",
        "                torch.tensor(row['target_token_idx'][0], dtype=torch.int64), # Target token indexes\n",
        "                torch.tensor(row['is_proper_gloss'],dtype=torch.int64)) # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGIjZzKHr3Pu"
      },
      "outputs": [],
      "source": [
        "class TokenClsFunction(Function):\n",
        "  \n",
        "    @staticmethod\n",
        "    def forward(ctx, input, target_token_tensor):\n",
        "        ctx.save_for_backward(input,target_token_tensor)\n",
        "        target_token_tensor.requires_grad = False\n",
        "        flattened_target_tensor = target_token_tensor.flatten()\n",
        "        return input[arange(flattened_target_tensor.shape[0]),flattened_target_tensor,:]\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input1,target_token_tensor = ctx.saved_tensors\n",
        "        grad = zeros_like(input1)\n",
        "        flattened_target_tensor = target_token_tensor.flatten()\n",
        "        # gradient only flows to specific indexes of target tensor\n",
        "        grad[arange(flattened_target_tensor.shape[0]),flattened_target_tensor,:] = grad_output\n",
        "        return grad, zeros_like(target_token_tensor)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrzs03nSsBEE"
      },
      "outputs": [],
      "source": [
        "class TokenClsLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TokenClsLayer, self).__init__()\n",
        "        self.tcf = TokenClsFunction.apply\n",
        "        \n",
        "    def forward(self, features, token_indexes):        \n",
        "        return self.tcf(features,token_indexes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "benY5QnFsFUi"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.config = BertConfig()\n",
        "        self.num_labels = 2\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.tokenselectlayer = TokenClsLayer()\n",
        "        self.linear = nn.Linear(768, self.num_labels)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        nn.init.xavier_normal_(self.linear.weight)\n",
        "        #self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, input_id, mask,_target_token_ids):\n",
        "        _encoded_layers, pooled_output = self.bert(input_id, mask)\n",
        "        _target_token_embeddings = self.tokenselectlayer(_encoded_layers,_target_token_ids)\n",
        "        dropout_output = self.dropout(_target_token_embeddings)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.softmax(linear_output)\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMG62wnLsFbV"
      },
      "outputs": [],
      "source": [
        "df = df_train[['input_ids','sent_indexes','target_token_idx','is_proper_gloss']]\n",
        "\n",
        "train_df, val_df =  train_test_split(df, \n",
        "                                        random_state=None, \n",
        "                                        test_size=.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGAcoTpi8A-y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrnZzoxTsFgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = CorpusDataset(train_data), CorpusDataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "    q = False\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for b_tokens_tensor, b_sentence_tensor, b_target_token_tensor,train_label  in tqdm(train_dataloader):\n",
        "                b_tokens_tensor=b_tokens_tensor.to(device)\n",
        "                b_sentence_tensor=b_sentence_tensor.to(device)\n",
        "                b_target_token_tensor=b_target_token_tensor.to(device)\n",
        "                train_label=train_label.to(device)\n",
        "\n",
        "                output = model(b_tokens_tensor, \n",
        "                               b_sentence_tensor, \n",
        "                               b_target_token_tensor)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_b_tokens_tensor, val_b_sentence_tensor, val_b_target_token_tensor,val_label in val_dataloader:\n",
        "\n",
        "                    val_b_tokens_tensor = val_b_tokens_tensor.to(device)\n",
        "                    val_b_sentence_tensor = val_b_sentence_tensor.to(device)\n",
        "                    val_b_target_token_tensor = val_b_target_token_tensor.to(device)\n",
        "                    val_label = val_label.to(device)\n",
        "                    \n",
        "\n",
        "                    output = model(val_b_tokens_tensor, val_b_sentence_tensor, val_b_target_token_tensor)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S4AxO2NsFmG",
        "outputId": "b5c77122-a2be-4ba8-ca2e-aa7d59d152c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 150791.57B/s]\n",
            "100%|██████████| 440473133/440473133 [00:11<00:00, 37796352.44B/s]\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "VmHBHu4Kr3Ly",
        "outputId": "5420a4e9-30af-418c-d243-2054bc811a99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/1892 [06:03<1:48:30,  3.63s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-ccc738615bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-8c34dd5ba863>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 output = model(b_tokens_tensor, \n\u001b[1;32m     32\u001b[0m                                \u001b[0mb_sentence_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                b_target_token_tensor)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-9e8e712d435d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_id, mask, _target_token_ids)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_target_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0m_encoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0m_target_token_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenselectlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_encoded_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_target_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdropout_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_target_token_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    708\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model, train_df, val_df, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "g1mAGCIXhCHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XrZGlVjwQXE"
      },
      "outputs": [],
      "source": [
        "# create an iterator object with write permission - model.pkl\n",
        "modelsavepath='./notebooks/data/preprocessed/model.pkl'\n",
        "with open(modelsavepath, 'wb') as files:\n",
        "    pickle.dump(model, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdnDbJ3wr3IC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NGpwOwYr3EY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdqUwzw3r3BW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akA3IOinr2yc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Bert Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}